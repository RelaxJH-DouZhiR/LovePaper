# Exploring the Potential of ChatGPT in Automated Code Refinement: An Empirical Study
- ICSE 2024

- [paper](https://arxiv.org/pdf/2309.08221)

- Qwen2.5 & ChatGPT4o

- [x] 人工修正

## 动机

本文旨在探索ChatGPT在自动化代码审查任务中的潜力。尽管ChatGPT在自然语言处理任务中表现出色，但在代码审查领域的表现尚不清楚。通过这项研究，作者希望填补这一空白，并提供关于如何利用大型语言模型提高代码质量的见解。

## 创新点

1. 进行了首次针对ChatGPT在基于代码审查评论的代码改进任务上的性能评估的实证研究。
2. 分析了ChatGPT在代码改进任务中面临的挑战，并提出了潜在的缓解策略。
3. 构建了一个新的高质量代码审查数据集，有助于未来的研究工作。

## 详细方法

<u>首先</u>，选择现有的基准测试CodeReview，并构建了一个新的高质量代码审查数据集。\
<u>然后</u>，使用最先进的代码审查工具CodeReviewer作为与ChatGPT比较的基线。\
<u>其次</u>，评估了不同提示和温度设置对ChatGPT在代码优化任务中精确匹配（EM）得分的影响，发现较低的温度设置可以产生更好、更稳定的结果，而在提示中描述代码审查场景有助于提高ChatGPT的表现。\
<u>最后</u>，创建了一个新的数据集，通过从未包含在标准基准中的仓库收集代码审查以及从包含在标准基准中的相同仓库收集近期的代码审查。

## 研究问题

1. <u>提示和温度对ChatGPT的影响如何？</u>
2. ChatGPT在基于代码审查的自动代码优化任务中的性能如何？
3. ChatGPT在哪些方面表现良好，又在哪些方面存在挑战？
4. <u>ChatGPT为何表现不佳，根本原因和解决方案是什么？</u>

### 评价指标

EM(Exact Match)和BLEU(Bilingual Evaluation Understudy)得分被用作评估模型在代码优化任务中性能的主要指标。\
<u>EM强调生成内容与标准答案的完全一致性，而BLEU则关注生成内容与标准答案之间的相似度。</u>

### 每个研究问题的结果

1. <u>参数和温度的配置对 ChatGPT 在代码优化中的表现有显著影响。在大多数情况下，较低的温度设置往往会产生更好且更稳定的结果。包含简洁场景描述的提示通常会产生更好的效果。
我们选出了 5 个效果最好、最具代表性的提示：\
(1) Prompt 1 (P1)：最简单的提示。我们只提供了基于旧代码和评审生成新代码的基本要求，没有额外的描述。\
(2) Prompt 2 (P2)：P1 + 场景描述。P2 基于 Prompt 1 设计，但包含了场景描述，要求 ChatGPT 扮演开发者角色，并根据来自团队领导的拉取请求中的评审信息修改代码。\
(3) Prompt 3 (P3)：P1 + 详细要求。P3 包含了详细的要求信息，例如尽可能保持代码的原始内容和格式，不补全旧代码中的任何代码片段，也不修改评审中未提及的代码。\
(4) Prompt 4 (P4)：P1 + 简明要求。类似于 P3，P4 也包含要求信息，但更为简洁。\
(5) Prompt 5 (P5)：P4 + 场景描述。P5 是 Prompt 2 和 Prompt 4 的结合，包含了场景描述和要求信息。</u>
2. 为了评估ChatGPT的性能，研究者们使用了新构建的数据集，并与最先进的代码审查工具CodeReviewer进行了比较。<u>结果显示，ChatGPT在应用于未见过的数据集时，表现出比CodeReviewer更好的泛化能力。然而，其有效性仍然有限，EM-trim和BLEU-trim分数仅为 22.78 和 76.55。</u>
3. 该实验通过开发标注网站、两位作者独立标注并通过第三方讨论解决分歧，基于三个维度（评论相关性、评论信息和代码变更类别）对 CodeReview 数据集中的样本进行定性分析，以评估 ChatGPT 的优缺点，并通过 Cohen's Kappa 系数验证标注一致性。ChatGPT在包含具体建议的高质量评审上表现更好，而在相关性低且信息量少的评审中表现较差。此外，ChatGPT在代码重构任务上表现最佳，而在涉及文档和功能优化的任务上表现较低。
4. <u>我们分析中发现的主要根本原因是缺乏领域知识、位置不明确以及变更不清晰。为缓解这些问题，确定了两个潜在方向：一是改进大型语言模型，例如使用 GPT-4 代替 GPT-3.5，二是提高评审质量，提供更清晰的信息。</u>

## 有效性威胁

1. 基准模型和基准的选择可能对结果的有效性构成威胁，研究者通过选择最先进的方法作为参考并创建具有更严格筛选规则的新测试数据集CRN来解决这一问题。
2. ChatGPT预测的随机性也是另一个潜在的威胁，研究者通过在RQ1中每种设置运行十次来减轻这一问题，但由于访问ChatGPT API的成本较高，在RQ2中没有重复运行。
3. 提示设置可能构成威胁，因为可能存在不合适的提示设置影响结果。

## 未来展望

虽然ChatGPT在代码审查任务中展现出了有希望的结果，但仍有许多改进的空间。未来的研究方向包括自动生产高质量的代码审查、审查精细化以及自动检测和过滤低质量的代码审查。此外，研究还强调了现有评估指标（如EM和BLEU）的局限性，指出了开发更加准确可靠的评估模型性能指标的必要性。