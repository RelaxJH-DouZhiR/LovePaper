# Chain-of-thought prompting elicits reasoning in large language models

- Advances in neural information processing systems 35 (2022)

- [paper](https://proceedings.neurips.cc/paper_files/paper/2022/file/9d5609613524ecf4f15af0f7b31abca4-Paper-Conference.pdf)

- Qwen2.5 & ChatGPT4o

- [ ] 人工修正

## 动机

本文的写作动机在于探索如何通过生成思维链——一系列中间推理步骤——来显著提升大型语言模型执行复杂推理任务的能力。具体来说，作者们展示了一种简单的方法，即思维链提示（chain-of-thought prompting），通过提供几个思维链示例作为提示中的示范，可以自然地在足够大的语言模型中激发这种推理能力。研究者们希望通过这种方法，不仅能够提高模型解决数学文字题、常识推理及符号推理等任务的表现，还能进一步理解大型语言模型在复杂任务上的潜力与局限。实验结果显示，对于几种大型语言模型而言，仅需少量的思维链示例就能大幅提高它们在不同推理任务上的表现，甚至超过了经过微调的GPT-3模型。这表明思维链提示方法在提升模型性能方面具有重要价值。

## 创新点

- 提出了思维链提示（Chain-of-Thought Prompting）方法
- 在多个基准测试中展示了思维链提示的有效性
- 提出了无需额外训练的通用推理方法
- 提供了模型推理过程的可解释性
- 验证了提示顺序和风格的鲁棒性
- 展示了思维链提示在符号推理任务中的潜力

## 与现有方法的区别

- 思维链生成方式：与以往需要从头训练或微调预训练模型以生成自然语言中间步骤的方法不同，本文提出的思维链提示方法能够在无需额外训练的情况下，通过提供少量的思维链示例，促使大型语言模型自动生成类似的推理过程。
- 适用性和通用性：相比特定任务的微调方法，思维链提示方法具有更高的通用性，适用于包括算术推理、常识推理和符号推理在内的多种任务，且不依赖于特定的数据集或任务类型。
- 模型规模的影响：本文强调了模型规模对思维链提示效果的重要性，指出只有当模型达到一定规模时，思维链提示才能有效促进其推理能力的提升。而传统的微调方法通常不会特别关注模型规模对最终效果的影响。
- 成本效益：与创建大量高质量的中间步骤数据集相比，思维链提示方法的成本较低，因为它只需要少数几个高质量的示例即可激发模型的推理能力，这使得该方法在实际应用中更具可行性。
- 零样本和少样本学习：传统的方法往往需要大量的标注数据进行微调，而思维链提示则利用了大型语言模型的上下文学习能力，能够在几乎没有额外训练的情况下实现任务解决，这对于资源有限或难以获取大规模标注数据的场景尤为重要。
- 泛化能力：在符号推理任务中，本文方法不仅能够处理标准情况下的任务，还能有效地应对超出训练样本长度的序列，展现了更强的泛化能力。这是传统方法难以实现的。

## 详细方法

首先，提出思维链提示方法：
论文首先介绍了思维链提示（Chain-of-Thought Prompting）这一方法。思维链提示是通过在模型提示中加入自然语言形式的中间推理步骤，帮助大型语言模型分解复杂问题。论文指出，在处理诸如算术推理、常识推理和符号推理等任务时，模型通过生成逐步的推理过程能够显著提升其性能。
然后，设计实验验证思维链提示的有效性：

论文通过三个主要任务类型来验证思维链提示的有效性：
算术推理：模型通过思维链提示解决数学词题。这些问题通常需要多个步骤的推理过程，例如分解、计算和合并答案。
常识推理：测试模型在具有常识背景知识问题上的表现，评估其是否能够推理出人类认为合乎常识的答案。
符号推理：测试模型在符号操作任务中的能力，如字母串联和硬币翻转问题，这些任务虽然看似简单，但对模型的符号处理能力提出了较高要求。
接着，使用大型预训练模型进行实验：

实验使用了多个大型语言模型，包括GPT-3、PaLM、LaMDA等，模型规模从数亿到5400亿参数不等。实验主要通过对比思维链提示和标准提示（即直接生成答案的提示方式）的效果来分析不同模型在多个任务中的表现。
实验中，思维链提示的具体实现：

论文将思维链提示的结构定义为〈输入、链式推理、输出〉，模型通过少量示例学习如何在推理过程中生成中间步骤。研究者人工编写了几个典型的推理示例，将这些示例作为“少量提示”，输入给模型，以展示模型应如何进行思维链。
然后，分析模型规模对思维链提示的影响：

论文探讨了思维链提示在不同规模的模型上表现的变化。实验表明，小规模模型（<100B参数）在思维链提示上的提升有限，而大型模型（如PaLM 540B）能够显著提高其推理能力，表明思维链提示是一种依赖模型规模的涌现能力。
最后，进行错误分析和鲁棒性测试：

论文还通过手动分析模型生成的推理链，研究哪些情况下推理错误。研究发现，模型生成的推理链大多数是合理的，但也存在一些细微错误。此外，论文还测试了不同提示顺序、风格以及不同任务上的表现，发现思维链提示对这些变化具有较高的鲁棒性。究方向提出了建议。

## 研究问题

**RQ1.** 大型语言模型的推理能力如何被挖掘？
**RQ2.** 思维链提示在不同推理任务中的有效性如何？
**RQ3.** 思维链提示与模型规模的关系是什么？
**RQ4.** 思维链提示如何改进基准测试中的表现？
**RQ5.** 思维链提示是否具有通用性？
**RQ6.** 思维链提示的鲁棒性如何？

### 评价指标

- 解决率 (Solve Rate)：在算术推理任务（如GSM8K基准测试）中，解决率是主要的评价指标。该指标表示模型能够正确回答问题的比例。论文通过这一指标评估了标准提示与思维链提示在解决数学问题时的表现。
- 准确率 (Accuracy)：在常识推理和符号推理任务（如CSQA和Sports Understanding基准测试）中，使用准确率作为评价指标。准确率表示模型给出的预测与正确答案匹配的比例。
任务基准表现 (Benchmark Performance)：
- 模型扩展曲线 (Scaling Curves)：论文展示了随着模型参数规模的增加，思维链提示与标准提示在解决不同任务上的表现变化。该扩展曲线用于评估模型规模对思维链提示性能提升的影响。
- 错误分析 (Error Analysis)：通过对生成的思维链提示进行手动分析，论文研究了模型在哪些情况下犯错，并通过分析推理过程中的逻辑错误来判断思维链提示的有效性。

### 每个研究问题的结果

**RQ1.**
实验介绍：
实验方法：论文提出了一种称为“思维链提示”（Chain-of-Thought Prompting）的方法，用于激发大型语言模型的推理能力。通过给出少量的输入-中间推理过程-输出的示例，模型能够生成复杂推理问题的中间步骤，从而提升其推理能力。
实验设置：研究选择了多个任务，包括算术推理（数学词题）、常识推理和符号推理，来测试思维链提示的有效性。
实验结果：
结果总结：实验结果表明，思维链提示显著提升了大型语言模型的推理能力，尤其是在需要多步骤推理的任务上。该方法在数学问题、常识推理和符号推理任务中均表现出强大的推理能力，超过了传统提示方法。

**RQ2.**
实验介绍：
算术推理实验：研究使用了五个数学问题数据集，包括GSM8K、SVAMP、ASDiv、AQuA和MAWPS，测试模型在这些问题上的推理能力。实验通过思维链提示和标准提示进行对比。
常识推理实验：在CSQA和StrategyQA等常识推理数据集上，思维链提示被用来帮助模型进行多步推理。
符号推理实验：测试了模型在解决符号推理任务中的能力，如“字母串联”和“硬币翻转”问题。
实验结果：
算术推理：思维链提示显著提升了模型在GSM8K等基准测试上的表现，尤其是在GSM8K上达到了新的最优性能（PaLM 540B模型的解决率超过标准提示的两倍）。其他数据集的表现也有显著提升。
常识推理：在StrategyQA等任务上，思维链提示也显著提升了模型的推理能力（从69.4%提升到75.6%），并且在多个常识推理任务上接近或超过了现有最佳性能。
符号推理：对于符号推理任务，思维链提示帮助模型解决了更复杂的推理问题，如在“字母串联”和“硬币翻转”任务中取得接近100%的解决率。

**RQ3.**
实验介绍：
实验设置：论文分析了不同规模的模型在思维链提示下的表现，尤其是在算术推理任务（如GSM8K）的基准测试中，评估不同参数量的模型（如GPT-3 175B、PaLM 540B）的表现变化。
实验结果：
结果总结：实验表明，思维链提示是模型规模的涌现能力，即只有当模型规模足够大时，思维链提示才能显著改善推理性能。对于较小的模型（如小于100B参数的模型），思维链提示的效果并不明显，但在大规模模型上，思维链提示的表现提升显著。例如，PaLM 540B模型在GSM8K上的表现显著优于175B模型。

**RQ4.**
实验介绍：
实验设置：在多个算术推理、常识推理和符号推理基准测试中，研究对比了思维链提示和标准提示的性能。实验包括GSM8K、SVAMP、ASDiv等数学问题数据集，以及CSQA、StrategyQA等常识推理任务。
实验结果：
结果总结：思维链提示在大多数基准测试上都超越了标准提示的表现，尤其在GSM8K、SVAMP和MAWPS等算术推理任务上，达到了新的最优性能。此外，常识推理和符号推理任务的表现也显著提高。

**RQ5.**
实验介绍：
实验设置：研究测试了思维链提示在不同推理任务（算术、常识、符号推理）中的通用性，评估其是否适用于广泛的推理任务。
实验结果：
结果总结：实验结果显示，思维链提示能够适用于广泛的推理任务，从多步骤的算术问题到常识推理再到符号推理，均表现出较强的通用性。这表明思维链提示是一种通用的推理方法。

**RQ6.**
实验介绍：
实验设置：为了测试思维链提示的鲁棒性，论文评估了不同提示顺序、不同提示风格以及不同的思维链示例对模型表现的影响。此外，还评估了模型在面对不同任务和模型规模时的表现变化。
实验结果：
结果总结：思维链提示表现出较高的鲁棒性，无论是不同提示词顺序还是不同风格的提示示例，思维链提示都能在大多数任务上保持显著的性能提升。此外，思维链提示在面对不同规模模型时也表现出较好的适应性。

## 有效性威胁

推理过程的正确性不稳定：
虽然思维链提示能够帮助模型生成中间推理步骤，但这些步骤并不总是正确的。生成的推理链中可能会包含逻辑或数学上的错误，导致模型得出错误的结论。论文中提到，即便是生成了正确的答案，有时推理链也可能是偶然正确的，并不代表真实的推理过程。

模型规模的依赖性：
思维链提示的有效性强烈依赖于模型的规模。实验表明，小于100B参数的模型在使用思维链提示时，效果提升有限。这意味着对于实际应用，只有在使用非常大的模型时，思维链提示才能充分发挥其潜力，这大大增加了计算成本和资源需求。

人工提示的高成本：
思维链提示依赖于高质量的提示示例，而这些示例通常需要人工构建。构建合适的中间推理步骤比简单的输入-输出对复杂得多，因此在大规模应用中生成和维护这些提示的成本较高。

推理路径的解释性仍然有限：
尽管思维链提示为模型推理提供了一定程度的可解释性，能够展示中间步骤，但要完全解释模型内部的计算过程仍然是一个开放问题。这种部分可解释性可能不足以满足某些高要求的应用场景。

## 未来展望

更大规模模型的探索：
作者提出，随着模型规模的进一步扩大，思维链提示的推理能力可能会继续提升。因此，未来的研究可以探索更大规模的语言模型，研究它们是否能进一步改善推理任务的表现。

更广泛的任务适用性：
思维链提示的应用目前主要集中在算术、常识和符号推理上。未来的工作可以探索该方法是否能够应用于更广泛的任务领域，特别是那些依赖多步骤推理的任务，例如复杂的自然语言理解、代码生成、决策制定等领域。

改进生成的推理路径质量：
虽然思维链提示已经展示了其有效性，但生成的推理路径仍然可能出错。未来的研究可以探索如何进一步改进生成推理路径的准确性，例如通过引入自我一致性检查机制来确保中间步骤的正确性。

提升小规模模型的推理能力：
目前思维链提示主要在大规模模型上表现良好，作者认为未来可以研究如何让小规模模型也能利用这一方法进行有效推理。这可能需要通过模型架构改进或新的提示设计来减少对大规模模型的依赖。

自动生成提示示例：
为了减少人工构建提示示例的成本，未来的研究可以探索自动生成高质量提示示例的方法。通过自动化技术生成思维链提示的示例，可能有助于将该方法扩展到更大规模的任务和模型中。